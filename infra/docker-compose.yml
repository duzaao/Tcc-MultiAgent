services:
  # MongoDB database service
  mongo:
    image: mongo:6.0
    restart: unless-stopped
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db

  # FastAPI backend services (Auth & Flights)
  api:
    build:
      context: ../api
      dockerfile: Dockerfile
    env_file:
      - ../.env
    depends_on:
      - mongo
    ports:
      - "8001:8001"
      - "8002:8002"
    restart: unless-stopped

  # Multi-agent orchestrator service
  agent:
    build:
      context: ../agent
      dockerfile: Dockerfile
    env_file:
      - ../.env
    volumes:
      - ../mcp:/mcp:ro
      - ../front:/front:ro
      - ../questions.jsonl:/questions.jsonl:ro
      - ../multi_eval:/out
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_HOST=http://ollama:11434
    # Uncomment to enable local LLM (requires ollama service)
    # depends_on:
    #   - ollama
    # restart: "no"

  # Optional: Local LLM service via Ollama
  # Uncomment to enable and ensure GPU/compute device access
  # ollama:
  #   image: ollama/ollama:latest
  #   restart: unless-stopped
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   devices:
  #     - /dev/kfd:/dev/kfd
  #     - /dev/dri:/dev/dri
  #   group_add:
  #     - video
  #   privileged: true
  #   entrypoint: /bin/bash -c "ollama serve & sleep 5 && ollama pull llama3.2:3b && wait"

volumes:
  mongo_data:
  # ollama_data: